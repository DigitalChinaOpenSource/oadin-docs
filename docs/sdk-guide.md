# ğŸš€ Oadin SDK ä½¿ç”¨è¯´æ˜

> ğŸ“š æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•åœ¨ .NETï¼ˆC#ï¼‰å’Œ Node.js é¡¹ç›®ä¸­é›†æˆå’Œä½¿ç”¨ Oadinï¼ˆå¥¥ä¸æ¨¡å‹æ¡†æ¶ï¼‰SDKã€‚

## ğŸ“‘ ç›®å½•

- [ğŸŸ¦ DotnetLibï¼ˆC#ï¼‰](#dotnetlibc)
  - [ï¿½ å®‰è£…æœ¬åœ° NuGet åŒ…](#å®‰è£…æœ¬åœ°-nuget-åŒ…)
  - [ğŸ› ï¸ åŸºæœ¬ç”¨æ³•](#åŸºæœ¬ç”¨æ³•)
- [ï¿½ğŸŸ© NodeLibï¼ˆNode.jsï¼‰](#nodelibnodejs)
  - [ğŸ“¦ å®‰è£…](#å®‰è£…)
  - [ğŸ› ï¸ åŸºæœ¬ç”¨æ³•](#åŸºæœ¬ç”¨æ³•-1)
- [ğŸ§© è¿›é˜¶åŠŸèƒ½](#è¿›é˜¶åŠŸèƒ½)
- [ğŸŒŸ å¸¸è§ API ç¤ºä¾‹](#å¸¸è§-api-ç¤ºoadin.CancelInstallModel(cancelData).then(console.log);

// å¸è½½æ¨¡å‹
oadin.DeleteModel(modelData).then(console.log);

// ============ 4. æœåŠ¡æä¾›å•†ç®¡ç† ============

// æŸ¥çœ‹æœåŠ¡æä¾›å•†[ğŸ“š æ›´å¤šç¤ºä¾‹ä¸é«˜çº§ç”¨æ³•](#æ›´å¤šç¤ºä¾‹ä¸é«˜çº§ç”¨æ³•)

# ğŸŸ¦ DotnetLibï¼ˆC#ï¼‰

### ğŸ“¦ å®‰è£…æœ¬åœ° NuGet åŒ…

1. æ‰“åŒ… NuGet åŒ…
   ```bash
   dotnet pack --configuration Release  
   ```

2. åˆ›å»ºæœ¬åœ°æºç›®å½•å¹¶å¤åˆ¶åŒ…
   ```bash
   mkdir local-nuget
   cp ./bin/Release/OadinClient.1.0.15.nupkg ./local-nuget
   ```

3. æ·»åŠ æœ¬åœ° NuGet æº
   ```bash
   dotnet nuget add source ./local-nuget --name LocalOadin
   ```

4. åœ¨é¡¹ç›®ä¸­å¼•ç”¨åŒ…
   ```bash
   dotnet add package OadinClient --version 1.0.15 --source LocalOadin
   ```

### ğŸ› ï¸ åŸºæœ¬ç”¨æ³•

ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº† Oadin C# SDK çš„å®Œæ•´ä½¿ç”¨æµç¨‹ï¼š

```csharp
using Oadin;

var client = new OadinClient();

// ============ 1. æœåŠ¡ç®¡ç† ============

// è·å–æœåŠ¡åˆ—è¡¨
var services = await client.GetServicesAsync();
Console.WriteLine(services);

// åˆ›å»ºæœåŠ¡
var requestData = new {
    service_name = "chat/embed/generate/text-to-image",
    service_source = "remote/local",
    service_provider_name = "local_ollama_chat",
    api_flavor = "ollama/openai/...",
    auth_type = "none/apikey/token/credentials",
    method = "GET/POST",
    desc = "æœåŠ¡æè¿°",
    url = "",
    auth_key = "your_api_key",
    skip_model = false,
    model_name = "llama2",
};
var result = await client.InstallServiceAsync(requestData);
Console.WriteLine(result);

// æ›´æ–°æœåŠ¡
var updateServiceData = new {
    service_name = "chat/embed/generate/text-to-image",
    hybrid_policy = "default/always_local/always_remote",
    remote_provider = "remote_openai_chat",
    local_provider = "local_ollama_chat"
};
var updateResult = await client.UpdateServiceAsync(updateServiceData);
Console.WriteLine(updateResult);

// ============ 2. æ¨¡å‹ç®¡ç† ============

// è·å–æ¨¡å‹åˆ—è¡¨
var models = await client.GetModelsAsync();
Console.WriteLine(models);

// æµå¼ä¸‹è½½æ¨¡å‹
var modelStreamRequest = new {
    model_name = "nomic-embed-text",
    service_name = "embed",
    service_source = "local",
    provider_name = "local_ollama_embed"
};
await client.InstallModelStreamAsync(
    modelStreamRequest,
    onData: (json) => Console.WriteLine("æµæ•°æ®: " + json),
    onError: (error) => Console.WriteLine("é”™è¯¯: " + error),
    onEnd: () => Console.WriteLine("æµå¼å®‰è£…å®Œæˆ")
);

// å–æ¶ˆæµå¼ä¸‹è½½æ¨¡å‹
var cancelRequest = new {
    model_name = "nomic-embed-text"
};
await client.CancelInstallModelAsync(cancelRequest);

// ä¸‹è½½æ¨¡å‹
var modelRequest = new {
    model_name = "llama2",
    service_name = "chat/embed/generate/text-to-image",
    service_source = "remote/local",
    provider_name = "local_ollama_chat/remote_openai_chat/..."
};
var installModelResult = await client.InstallModelAsync(modelRequest);
Console.WriteLine(installModelResult);

// å¸è½½æ¨¡å‹
var uninstallModelResult = await client.DeleteModelAsync(modelRequest);
Console.WriteLine(uninstallModelResult);

// è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆä»å¼•æ“ï¼‰
var modelsAvailable = await client.GetModelAvailiableAsync();
Console.WriteLine(modelsAvailable);

// è·å–æ¨èæ¨¡å‹åˆ—è¡¨
var modelsRecommended = await client.GetModelsRecommendedAsync();
Console.WriteLine(modelsRecommended);

// è·å–æ”¯æŒæ¨¡å‹åˆ—è¡¨
var modelsSupported = await client.GetModelsSupportedAsync();
Console.WriteLine(modelsSupported);

// ============ 3. æœåŠ¡æä¾›å•†ç®¡ç† ============

// æŸ¥çœ‹æœåŠ¡æä¾›å•†
var serviceProviders = await client.GetServiceProvidersAsync();
Console.WriteLine(serviceProviders);

// æ–°å¢æœåŠ¡æä¾›å•†
var providerRequest = new {
    service_name = "chat/embed/generate/text-to-image",
    service_source = "remote/local",
    flavor_name = "ollama/openai/...",
    provider_name = "local_ollama_chat/remote_openai_chat/...",
    desc = "æä¾›å•†æè¿°",
    method = "POST",
    url = "https://api.example.com",
    auth_type = "none/apikey/token/credentials",
    auth_key = "your_api_key",
    models = new[] { "qwen3:8b", "deepseek-r1:8b" },
    extra_headers = new { },
    extra_json_body = new { },
    properties = new { }
};
var addProviderResult = await client.AddServiceProviderAsync(providerRequest);
Console.WriteLine(addProviderResult);

// æ›´æ–°æœåŠ¡æä¾›å•†
var updateProviderResult = await client.UpdateServiceProviderAsync(providerRequest);
Console.WriteLine(updateProviderResult);

// åˆ é™¤æœåŠ¡æä¾›å•†
var deleteProviderRequest = new {
    provider_name = "local_ollama_chat/remote_openai_chat/..."
};
var deleteProviderResult = await client.DeleteServiceProviderAsync(deleteProviderRequest);
Console.WriteLine(deleteProviderResult);

// ============ 4. é…ç½®ç®¡ç† ============

// å¯¼å…¥é…ç½®æ–‡ä»¶
var importResult = await client.ImportConfigAsync("path/to/.oadin");
Console.WriteLine(importResult);

// å¯¼å‡ºé…ç½®æ–‡ä»¶
var exportRequest = new { };
var exportResult = await client.ExportConfigAsync(exportRequest);
Console.WriteLine(exportResult);

// ============ 5. AI æœåŠ¡è°ƒç”¨ ============

// æµå¼ Chat
var chatRequest = new {
    model = "deepseek-r1:7b",
    stream = true,
    messages = new[] {
        new { role = "user", content = "ä½ æ˜¯è°ï¼Ÿ" }
    }
};
await client.ChatAsync(
    chatRequest,
    isStream: true,
    onData: (data) => Console.WriteLine("æµæ•°æ®: " + data),
    onError: (error) => Console.WriteLine("é”™è¯¯: " + error),
    onEnd: () => Console.WriteLine("æµå¼è¯·æ±‚ç»“æŸ")
);

// éæµå¼ Chat
var chatRequest2 = new {
    model = "deepseek-r1:7b",
    stream = false,
    messages = new[] {
        new { role = "user", content = "ä½ æ˜¯è°ï¼Ÿ" }
    }
};
var chatResult = await client.ChatAsync(chatRequest2);
Console.WriteLine(chatResult);

// æµå¼ Generate
var generateRequest = new {
    model = "deepseek-r1:7b",
    stream = true,
    prompt = "è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"
};
await client.GenerateAsync(
    generateRequest,
    isStream: true,
    onData: (data) => Console.WriteLine("æµæ•°æ®: " + data),
    onError: (error) => Console.WriteLine("é”™è¯¯: " + error),
    onEnd: () => Console.WriteLine("ç”Ÿæ–‡æµå¼è¯·æ±‚ç»“æŸ")
);

// éæµå¼ Generate
var generateRequest2 = new {
    model = "deepseek-r1:7b",
    stream = false,
    prompt = "è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"
};
var generateResult = await client.GenerateAsync(generateRequest2);
Console.WriteLine(generateResult);

// embed
var embedRequest = new {
    model = "nomic-embed-text",
    input = new[] { "äºŒå½ªå­", "è¸¹çš®" }
};
var embedResult = await client.EmbedAsync(embedRequest);
Console.WriteLine(embedResult);

// text-to-image
var t2iRequest = new {
    model = "wanx2.1-t2i-turbo",
    prompt = "å–œæ¬¢ç©åŸƒå¾·åŠ è¹²è‰é‡Œæ”’å¤§æ‹›çš„å°å­¦ç”Ÿ"
};
var t2iResult = await client.TextToImageAsync(t2iRequest);
Console.WriteLine(t2iResult);

// ============ 6. è¾…åŠ©åŠŸèƒ½ ============

// æ£€æŸ¥ Oadin æœåŠ¡çŠ¶æ€
var isAvailable = await client.IsOadinAvailiableAsync();
Console.WriteLine($"Oadin æœåŠ¡å¯ç”¨: {isAvailable}");

// æ£€æŸ¥ Oadin æ˜¯å¦å·²ä¸‹è½½
var isExisted = client.IsOadinExisted();
Console.WriteLine($"Oadin å·²ä¸‹è½½: {isExisted}");
```

---

# ğŸŸ© NodeLibï¼ˆNode.jsï¼‰

### ğŸ“¦ å®‰è£…

åœ¨ Node é¡¹ç›®ä¸­å®‰è£…æœ¬åœ° tgz åŒ…ï¼š

```bash
npm install oadin-lib-1.2.67.tgz
```

### ğŸ› ï¸ åŸºæœ¬ç”¨æ³•

ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº† Oadin Node.js SDK çš„å®Œæ•´ä½¿ç”¨æµç¨‹ï¼Œä»åˆå§‹åŒ–åˆ°å„ç§ AI æœåŠ¡çš„è°ƒç”¨ï¼š

```javascript
const OadinLib = require('oadin-lib');
const oadin = new OadinLib();

// ============ 1. ç¯å¢ƒæ£€æŸ¥ä¸åˆå§‹åŒ– ============

// æ£€æŸ¥ oadin æœåŠ¡æ˜¯å¦å­˜åœ¨
oadin.IsOadinAvailiable().then(console.log);

// æ£€æŸ¥ oadin.exe æ˜¯å¦ä¸‹è½½
oadin.IsOadinExisted().then(console.log);

// ä¸‹è½½ oadin.exe
oadin.DownloadOadin().then(console.log);

// å¯åŠ¨ oadin æœåŠ¡
oadin.InstallOadin().then(console.log);

// å®‰è£… chat æœåŠ¡
oadin.InstallChat().then(console.log);

// ============ 2. æœåŠ¡ç®¡ç† ============

// è·å–æœåŠ¡åˆ—è¡¨
oadin.GetServices().then(console.log);

// åˆ›å»ºæ–°æœåŠ¡
const data = {
    service_name: "chat/embed/generate/text-to-image",
    service_source: "remote/local",
    hybrid_policy: "default/always_local/always_remote",
    flavor_name: "ollama/openai/...",
    provider_name: "local_ollama_chat/remote_openai_chat/...",
    auth_type: "none/apikey",
    auth_key: "your_api_key",
};
oadin.CreateService(data).then(console.log);

// æ›´æ–°æœåŠ¡
const updateData = {
    service_name: "chat/embed/generate/text-to-image",
    hybrid_policy: "default/always_local/always_remote",
    remote_provider: "remote_openai_chat",
    local_provider: "local_ollama_chat"
};
oadin.UpdateService(updateData).then(console.log);

// ============ 3. æ¨¡å‹ç®¡ç† ============

// è·å–æ¨¡å‹åˆ—è¡¨
oadin.GetModels().then(console.log);

// å®‰è£…æ¨¡å‹
const modelData = {
    model_name: "qwen3:8b",
    service_name: "chat/embed/generate/text-to-image",
    service_source: "remote/local",
    provider_name: "local_ollama_chat/remote_openai_chat/...",
};
oadin.InstallModel(modelData).then(console.log);

// å¸è½½æ¨¡å‹
oadin.DeleteModel(modelData).then(console.log);

// æŸ¥çœ‹æœåŠ¡æä¾›å•†
oadin.GetServiceProviders().then(console.log);

// æ–°å¢æœåŠ¡æä¾›å•†
const providerData = {
    service_name: "chat/embed/generate/text-to-image",
    service_source: "remote/local",
    flavor_name: "ollama/openai/...",
    provider_name: "local_ollama_chat/remote_openai_chat/...",
    desc: "",
    method: "POST",
    auth_type: "none/apikey",
    auth_key: "your_api_key",
    models: ["qwen3:8b", "deepseek-r1:8b"],
    extra_headers: {},
    extra_json_body: {},
    properties: {}
};
oadin.InstallServiceProvider(providerData).then(console.log);

// æ›´æ–°æœåŠ¡æä¾›å•†
oadin.UpdateServiceProvider(providerData).then(console.log);

// åˆ é™¤æœåŠ¡æä¾›å•†
oadin.DeleteServiceProvider({ provider_name: "local_ollama_chat/remote_openai_chat/..." }).then(console.log);

// ============ 5. é…ç½®ç®¡ç† ============

// å¯¼å…¥é…ç½®æ–‡ä»¶
oadin.ImportConfig("path/to/.oadin").then(console.log);

// å¯¼å‡ºé…ç½®æ–‡ä»¶
oadin.ExportConfig({ service_name: "chat/embed/generate/text-to-image" }).then(console.log);

// è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆæŸ¥çœ‹ollamaçš„æ¨¡å‹ï¼‰
oadin.GetModelsAvailiable().then(console.log);

// è·å–æ¨èæ¨¡å‹åˆ—è¡¨
oadin.GetModelsRecommended().then(console.log);

// è·å–æ”¯æŒæ¨¡å‹åˆ—è¡¨
oadin.GetModelsSupported().then(console.log);

// ============ 6. AI æœåŠ¡è°ƒç”¨ ============

// ChatæœåŠ¡ï¼ˆæµå¼ï¼‰
const chatData = {
    model: "deepseek-r1:8b",
    stream: true,
    messages: [
        { role: "user", content: "ä½ å¥½" }
    ],
    temperature: 0.7,
    max_tokens: 100,
};
oadin.Chat(chatData).then((chatStream) => {
    chatStream.on('data', (data) => {
        console.log(data);
    });
    chatStream.on('error', (error) => {
        console.error(error);
    });
    chatStream.on('end', () => {
        console.log('Chat stream ended');
    });
});

// ChatæœåŠ¡ï¼ˆéæµå¼ï¼‰
const chatData2 = {
    model: "deepseek-r1:8b",
    stream: false,
    messages: [
        { role: "user", content: "ä½ å¥½" }
    ],
    temperature: 0.7,
    max_tokens: 100,
};
oadin.Chat(chatData2).then(console.log);

// ç”Ÿæ–‡æœåŠ¡ï¼ˆæµå¼ï¼‰
const genData = {
    model: "deepseek-r1:8b",
    stream: true,
    prompt: "ä½ å¥½",
};
oadin.Generate(genData).then((generateStream) => {
    generateStream.on('data', (data) => {
        console.log(data);
    });
    generateStream.on('error', (error) => {
        console.error(error);
    });
    generateStream.on('end', () => {
        console.log('Generate stream ended');
    });
});

// ç”Ÿæ–‡æœåŠ¡ï¼ˆéæµå¼ï¼‰
const genData2 = {
    model: "deepseek-r1:8b",
    stream: false,
    prompt: "ä½ å¥½",
};
oadin.Generate(genData2).then(console.log);

// æ–‡ç”Ÿå›¾æœåŠ¡
const t2iData = {
    model: "wanx2.1-t2i-turbo",
    prompt: "ä¸€é—´æœ‰ç€ç²¾è‡´çª—æˆ·çš„èŠ±åº—ï¼Œæ¼‚äº®çš„æœ¨è´¨é—¨ï¼Œæ‘†æ”¾ç€èŠ±æœµ",
};
oadin.TextToImage(t2iData).then(console.log);
```

---

# ğŸ§© è¿›é˜¶åŠŸèƒ½

Oadin SDK æ”¯æŒä¸°å¯Œçš„è¿›é˜¶åŠŸèƒ½ï¼Œå¸®åŠ©å¼€å‘è€…çµæ´»é›†æˆå’Œæ‰©å±• AI æœåŠ¡ã€‚ä»¥ä¸‹ä¸ºä¸»è¦è¿›é˜¶èƒ½åŠ›åŠç”¨æ³•ç¤ºä¾‹ï¼š

## 1. æœåŠ¡/æ¨¡å‹çš„å®‰è£…ã€æ›´æ–°ä¸åˆ é™¤

- **å®‰è£…æœåŠ¡**ï¼šå‚è€ƒä¸Šæ–‡â€œå®‰è£…æœåŠ¡â€ç« èŠ‚ï¼Œå¯é€šè¿‡ `InstallServiceAsync` (C#) æˆ– `CreateService` (Node.js) å®‰è£…æœåŠ¡ã€‚
- **å®‰è£…æ¨¡å‹**ï¼š
  - C#ï¼š
    ```csharp
    var modelRequest = new {
        model_name = "llama2",
        service_name = "chat",
        service_source = "local",
        provider_name = "local_ollama_chat"
    };
    var result = await client.InstallModelAsync(modelRequest);
    ```
  - Node.jsï¼š
    ```javascript
    const modelData = {
        model_name: "llama2",
        service_name: "chat",
        service_source: "local",
        provider_name: "local_ollama_chat"
    };
    oadin.InstallModel(modelData).then(console.log);
    ```
- **åˆ é™¤æ¨¡å‹/æœåŠ¡**ï¼šåŒç†ï¼Œè°ƒç”¨ `DeleteModelAsync` æˆ– `DeleteServiceProviderAsync` ç­‰æ¥å£ã€‚

## 2. æµå¼å“åº”ä¸å›è°ƒ

- **C# æµå¼ Chat**ï¼š
  ```csharp
  await client.ChatAsync(
      chatRequest,
      isStream: true,
      onData: (data) => Console.WriteLine("æµæ•°æ®: " + data),
      onError: (error) => Console.WriteLine("é”™è¯¯: " + error),
      onEnd: () => Console.WriteLine("æµå¼è¯·æ±‚ç»“æŸ")
  );
  ```
- **Node.js æµå¼ Chat**ï¼š
  ```javascript
  oadin.Chat(chatData).then((chatStream) => {
      chatStream.on('data', (data) => {
          console.log(data);
      });
      chatStream.on('error', (error) => {
          console.error(error);
      });
      chatStream.on('end', () => {
          console.log('Chat stream ended');
      });
  });
  ```

## 3. é…ç½®å¯¼å…¥/å¯¼å‡ºä¸ä¸€é”®éƒ¨ç½²

- **å¯¼å…¥é…ç½®**ï¼š
  - C#ï¼š`ImportConfigAsync("path/to/.oadin")`
  - Node.jsï¼š`oadin.ImportConfig("path/to/.oadin")`
- **å¯¼å‡ºé…ç½®**ï¼š
  - C#ï¼š`ExportConfigAsync(new { })`
  - Node.jsï¼š`oadin.ExportConfig({ ... })`
- **ä¸€é”®éƒ¨ç½²**ï¼šå°† `.oadin` æ–‡ä»¶éšåº”ç”¨åˆ†å‘ï¼Œç›®æ ‡ç¯å¢ƒå¯¼å…¥å³å¯è‡ªåŠ¨å®‰è£…æ‰€æœ‰æœåŠ¡å’Œæ¨¡å‹ã€‚

## 4. ä¸»è¦å‚æ•°è¯´æ˜

| å‚æ•°å              | è¯´æ˜                       | ç¤ºä¾‹å€¼                      |
|---------------------|----------------------------|-----------------------------|
| service_name        | æœåŠ¡å                     | chat/embed/text-to-image    |
| service_source      | æœåŠ¡æ¥æº                   | local/remote                |
| provider_name       | æœåŠ¡æä¾›å•†å               | local_ollama_chat           |
| api_flavor          | API é£æ ¼                   | ollama/openai/...           |
| model_name          | æ¨¡å‹åç§°                   | llama2/deepseek-r1:8b       |
| auth_type           | é‰´æƒç±»å‹                   | none/apikey/token/credentials|
| auth_key            | é‰´æƒå¯†é’¥                   | your_api_key                 | method              | HTTP æ–¹æ³•                    | POST/GET                     |
| url                 | æœåŠ¡åœ°å€                   | http://localhost:11434/...   |
| stream              | æ˜¯å¦æµå¼                   | true/false                   |
| messages            | èŠå¤©æ¶ˆæ¯æ•°ç»„               | [{role: "user", ...}]        |
| input/prompt        | è¾“å…¥å†…å®¹                   | "ä½ å¥½"/"ä¸€åªçŒ«"               |

## 5. è¿›é˜¶ç”¨æ³•ä¸æœ€ä½³å®è·µ

- æ¨èå°†æœåŠ¡ã€æ¨¡å‹ã€Provider é…ç½®å†™å…¥ `.oadin` æ–‡ä»¶ï¼Œä¾¿äºå›¢é˜Ÿåä½œå’Œç¯å¢ƒè¿ç§»ã€‚
- æµå¼æ¥å£å»ºè®®é…åˆå‰ç«¯äº‹ä»¶æµæˆ–åç«¯å›è°ƒå¤„ç†ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚
- åˆç†é…ç½®æ··åˆç­–ç•¥ï¼Œå®ç°æœ¬åœ°å’Œè¿œç¨‹æœåŠ¡çš„è‡ªåŠ¨åˆ‡æ¢ã€‚
- å®šæœŸå¤‡ä»½é…ç½®æ–‡ä»¶ï¼Œä¾¿äºå¿«é€Ÿæ¢å¤æœåŠ¡ç¯å¢ƒã€‚

---

# ğŸŒŸ å¸¸è§ API ç¤ºä¾‹

### âš¡ å®‰è£…æœåŠ¡

#### ğŸŸ¦ C# ç¤ºä¾‹
```csharp
var requestData = new {
    service_name = "chat",
    service_source = "local",
    service_provider_name = "local_ollama_chat",
    api_flavor = "ollama",
};
var result = await client.InstallServiceAsync(requestData);
```

#### ğŸŸ© Node.js ç¤ºä¾‹
```javascript
const data = {
    service_name: "chat",
    service_source: "local",
    flavor_name: "ollama",
    provider_name: "local_ollama_chat",
};
oadin.CreateService(data).then(console.log);
```

### ğŸ’¬ èŠå¤©æœåŠ¡è°ƒç”¨

#### ğŸŒ HTTP API ç¤ºä¾‹
```http
POST http://127.0.0.1:16688/oadin/v0.2/services/chat
Content-Type: application/json

{
    "model": "deepseek-r1:8b",
    "stream": true,
    "messages": [
        { "role": "user", "content": "ä½ å¥½ï¼" },
        { "role": "assistant", "content": "ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼" },
        { "role": "user", "content": "ä½ æ˜¯è°ï¼Ÿ" }
    ],
    "think": true
}
```

---

## ğŸ“š æ›´å¤šç¤ºä¾‹ä¸é«˜çº§ç”¨æ³•

### 1. å¤šè½®å¯¹è¯ä¸ä¸Šä¸‹æ–‡ç®¡ç†
Oadin æ”¯æŒå¤šè½®å¯¹è¯ï¼Œ`messages` å‚æ•°å¯ä¼ é€’å†å²æ¶ˆæ¯ï¼Œå®ç°ä¸Šä¸‹æ–‡è¿ç»­ã€‚

### 2. è¿›é˜¶ Chat/Embed/Generate ç”¨æ³•
- æ”¯æŒ `stream: true` æµå¼å“åº”ï¼Œæå‡å‰ç«¯ä½“éªŒ
- æ”¯æŒ `think: true` å¼€å¯æ€è€ƒæ¨¡å¼ï¼Œå½“æ¨¡å‹æ”¯æŒå…³é—­æ·±åº¦æ€è€ƒæ—¶ï¼Œå¯è®¾ç½®ä¸º false æ¥å…³é—­ï¼Œæé«˜å›ç­”é€Ÿåº¦ã€‚
- æ”¯æŒè‡ªå®šä¹‰ `auth_type`ã€`auth_key`ã€`extra_headers`ã€`extra_json_body` ç­‰é«˜çº§å‚æ•°
- æ”¯æŒå¤š Providerã€è‡ªåŠ¨è·¯ç”±ã€æ··åˆç­–ç•¥

### 3. å¸¸è§é—®é¢˜æ’æŸ¥ ğŸ”§

| é—®é¢˜ç±»å‹ | ç—‡çŠ¶ | è§£å†³æ–¹æ¡ˆ |
|---------|------|---------|
| **æœåŠ¡æœªå¯åŠ¨** | è¿æ¥è¢«æ‹’ç»ã€è¶…æ—¶ | 1. ç¡®è®¤ `oadin server start` å·²è¿è¡Œ<br>2. æ£€æŸ¥è¿›ç¨‹ï¼š`ps aux \| grep oadin`<br>3. é‡å¯æœåŠ¡ï¼š`oadin server restart` |
| **ç«¯å£å†²çª** | Address already in use | 1. æ£€æŸ¥ 16688 ç«¯å£å ç”¨ï¼š`netstat -tulpn \| grep 16688`<br>2. ä¿®æ”¹é…ç½®æ–‡ä»¶ç«¯å£<br>3. ç»ˆæ­¢å†²çªè¿›ç¨‹ |
| **æ¨¡å‹ä¸‹è½½å¤±è´¥** | ç½‘ç»œé”™è¯¯ã€ä¸‹è½½ä¸­æ–­ | 1. æ£€æŸ¥ç½‘ç»œè¿æ¥<br>2. éªŒè¯ Provider é…ç½®<br>3. é‡è¯•ä¸‹è½½æˆ–ä½¿ç”¨æµå¼ä¸‹è½½ |
| **è®¤è¯å¤±è´¥** | 401/403 é”™è¯¯ | 1. æ£€æŸ¥ `auth_key` é…ç½®<br>2. éªŒè¯ `auth_type` è®¾ç½®<br>3. ç¡®è®¤ API å¯†é’¥æœ‰æ•ˆæ€§ |
| **æ¨¡å‹ä¸å­˜åœ¨** | 404 é”™è¯¯ | 1. æ£€æŸ¥æ¨¡å‹åç§°æ‹¼å†™<br>2. ç¡®è®¤æ¨¡å‹å·²å®‰è£…<br>3. æŸ¥çœ‹å¯ç”¨æ¨¡å‹åˆ—è¡¨ |

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚éœ€æ›´è¯¦ç»†çš„æ¥å£å‚æ•°ã€è¿›é˜¶ç”¨æ³•ç­‰ï¼Œè¯·å‚è€ƒæœ¬ SDK æ–‡æ¡£å‰è¿°ç« èŠ‚ï¼Œæˆ–é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»æŠ€æœ¯æ”¯æŒï¼š

- ğŸ“§ **é‚®ç®±æ”¯æŒ**ï¼šæäº¤è¯¦ç»†é—®é¢˜æè¿°å’Œé”™è¯¯æ—¥å¿—
- ğŸ’¬ **åœ¨çº¿æ–‡æ¡£**ï¼šæŸ¥çœ‹æœ€æ–°APIå‚è€ƒå’Œç¤ºä¾‹  
- ğŸ› **é—®é¢˜åé¦ˆ**ï¼šæŠ¥å‘Š Bug æˆ–æå‡ºåŠŸèƒ½å»ºè®®

> ğŸ’¡ **æç¤º**ï¼šæŠ¥å‘Šé—®é¢˜æ—¶ï¼Œè¯·æä¾› Oadin ç‰ˆæœ¬å·ã€æ“ä½œç³»ç»Ÿã€é”™è¯¯æ—¥å¿—ç­‰ä¿¡æ¯ï¼Œä»¥ä¾¿å¿«é€Ÿå®šä½å’Œè§£å†³é—®é¢˜ã€‚
